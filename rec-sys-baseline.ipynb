{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "875b9306",
   "metadata": {},
   "source": [
    "# Recommender Systems Baseline\n",
    "\n",
    "> NOTEBOOK IS INCOMPLETE, MAY NOT RUN\n",
    "\n",
    "Notebook covers the user-based KNN and SVD recommender systems to compare against the Social Media Recommender Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "03e1c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, KNNBasic, SVD\n",
    "from surprise.model_selection import cross_validate, train_test_split, LeaveOneOut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa9b40e",
   "metadata": {},
   "source": [
    "## Data loading and exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a95f6e28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>repo_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x00evil</td>\n",
       "      <td>0xAX/linux-insides</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x00evil</td>\n",
       "      <td>30-seconds/30-seconds-of-code</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x00evil</td>\n",
       "      <td>996icu/996.ICU</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x00evil</td>\n",
       "      <td>AFNetworking/AFNetworking</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x00evil</td>\n",
       "      <td>AUTOMATIC1111/stable-diffusion-webui</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id                               repo_id  rating\n",
       "0  0x00evil                    0xAX/linux-insides       0\n",
       "1  0x00evil         30-seconds/30-seconds-of-code       0\n",
       "2  0x00evil                        996icu/996.ICU       0\n",
       "3  0x00evil             AFNetworking/AFNetworking       0\n",
       "4  0x00evil  AUTOMATIC1111/stable-diffusion-webui       0"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/user_repo_ratings_full.csv', \n",
    "                 names=['user_id', 'repo_id', 'rating'], \n",
    "                 skiprows=1)\n",
    "\n",
    "# df = pd.read_csv('./user-item-ratings.csv', \n",
    "#                  names=['user_id', 'repo_id', 'rating'], \n",
    "#                  skiprows=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "fa098023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>repo_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0x00evil</td>\n",
       "      <td>SwiftGGTeam/the-swift-programming-language-in-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0x00evil</td>\n",
       "      <td>atom/atom</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0x00evil</td>\n",
       "      <td>capistrano/capistrano</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0x00evil</td>\n",
       "      <td>git/git</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0x00evil</td>\n",
       "      <td>golang/go</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0x00evil</td>\n",
       "      <td>jekyll/jekyll</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0x00evil</td>\n",
       "      <td>rails/rails</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0x00evil</td>\n",
       "      <td>scrapy/scrapy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0x00evil</td>\n",
       "      <td>sinatra/sinatra</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0x00evil</td>\n",
       "      <td>spree/spree</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0x00evil</td>\n",
       "      <td>torvalds/linux</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                                            repo_id  rating\n",
       "28   0x00evil  SwiftGGTeam/the-swift-programming-language-in-...       1\n",
       "53   0x00evil                                          atom/atom       1\n",
       "64   0x00evil                              capistrano/capistrano       1\n",
       "110  0x00evil                                            git/git       1\n",
       "115  0x00evil                                          golang/go       1\n",
       "140  0x00evil                                      jekyll/jekyll       1\n",
       "211  0x00evil                                        rails/rails       1\n",
       "226  0x00evil                                      scrapy/scrapy       1\n",
       "231  0x00evil                                    sinatra/sinatra       1\n",
       "238  0x00evil                                        spree/spree       1\n",
       "254  0x00evil                                     torvalds/linux       1"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['user_id'] == '0x00evil') & df['rating'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6ca695fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total obs: 316064\n",
      "Total users: 1162\n",
      "Total repos: 272\n"
     ]
    }
   ],
   "source": [
    "n_users = df.user_id.unique().shape[0]\n",
    "n_repos = df.repo_id.unique().shape[0]\n",
    "\n",
    "print(f'Total obs: {df.shape[0]}')\n",
    "print(f'Total users: {n_users}')\n",
    "print(f'Total repos: {n_repos}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f578aeac",
   "metadata": {},
   "source": [
    "## Prep data for Rec Sys\n",
    "\n",
    "Data has already been loaded in as a sparse matrix, we collect the per repo rankings, that is those repositories with most stars (1.0) in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "13f75ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "repo_id\n",
       "twbs/bootstrap                            168\n",
       "EbookFoundation/free-programming-books    147\n",
       "d3/d3                                     109\n",
       "nodejs/node-v0.x-archive                  104\n",
       "sindresorhus/awesome                      102\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_rankings = df.groupby(['repo_id']).rating.sum().sort_values(ascending=False)\n",
    "repo_rankings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0773cf43",
   "metadata": {},
   "source": [
    "# CUSTOM RECOMMENDERS\n",
    "\n",
    "Follower-following based recommender systems here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc691cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87a2b884",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Each one of the following models serves as a baseline for comparison with social media contexts. The algorithms used are KNNBasic and SVD. Even though other methods may prove stronger, these are two algorithms that directly relate to the social media context and will therefore be easier to compare.\n",
    "\n",
    "For both algorithms, we use default values and perform 5-fold cross validation to obtain the RMSE and MAE. \n",
    "\n",
    "### Ratings scale\n",
    "\n",
    "> IGNORE THIS SECTION\n",
    "\n",
    "The ratings scale is 0 if a user has not starred a given repository or 1 if they have starred a given repository. This is akin to friend recommendations and allows us to utilise open triads in the social graphs.\n",
    "\n",
    "In order to produce cosine sims, the ratings were scaled to 1 (not starred), 2 (starred).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ee1debdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>repo_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x00evil</td>\n",
       "      <td>0</td>\n",
       "      <td>0xAX/linux-insides</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x00evil</td>\n",
       "      <td>0</td>\n",
       "      <td>30-seconds/30-seconds-of-code</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x00evil</td>\n",
       "      <td>0</td>\n",
       "      <td>996icu/996.ICU</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x00evil</td>\n",
       "      <td>0</td>\n",
       "      <td>AFNetworking/AFNetworking</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x00evil</td>\n",
       "      <td>0</td>\n",
       "      <td>AUTOMATIC1111/stable-diffusion-webui</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_name  user_id                             repo_name  repo_id  rating\n",
       "0  0x00evil        0                    0xAX/linux-insides        0       1\n",
       "1  0x00evil        0         30-seconds/30-seconds-of-code        1       1\n",
       "2  0x00evil        0                        996icu/996.ICU        2       1\n",
       "3  0x00evil        0             AFNetworking/AFNetworking        3       1\n",
       "4  0x00evil        0  AUTOMATIC1111/stable-diffusion-webui        4       1"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alter the ratings? - this has to be done to compute cosine sims, the distance remains the same so it shouldnt be a problem\n",
    "temp = df.copy()\n",
    "temp['rating'] = temp['rating']+1\n",
    "\n",
    "temp['user_id'] = temp['user_id'].astype('category')\n",
    "temp['repo_id'] = temp['repo_id'].astype('category')\n",
    "\n",
    "# ulabels, ulevels = pd.factorize(temp['user_id'])\n",
    "# rlabels, rlevels = pd.factorize(temp['repo_id'])\n",
    "temp = pd.DataFrame({\n",
    "    'user_name': temp['user_id'],\n",
    "    'user_id': temp['user_id'].cat.codes,\n",
    "    'repo_name': temp['repo_id'],\n",
    "    'repo_id': temp['repo_id'].cat.codes,\n",
    "    'rating': temp['rating']\n",
    "})\n",
    "\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8a746f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from surprise import accuracy\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class EData:\n",
    "    def __init__(self, data, rankings):\n",
    "        # Generate entire training set for evaluating properties \n",
    "        self.full_trainset = data.build_full_trainset()\n",
    "        self.full_anti_testset = self.full_trainset.build_anti_testset()\n",
    "        \n",
    "        # Set rankings\n",
    "        self.rankings = rankings\n",
    "        \n",
    "        # Generate a train (75) / test (25) split for measuring accuracy\n",
    "        self.trainset, self.testset = train_test_split(data, test_size=0.25, random_state=1)\n",
    "        \n",
    "        # Create leave-one-out train/test split for eval of top-N recs\n",
    "        # and we create an anti-test-set for generating predictions\n",
    "        LOOCV = LeaveOneOut(n_splits=1, random_state=1)\n",
    "        for train, test in LOOCV.split(data):\n",
    "            self.LOOCVTrain = train\n",
    "            self.LOOCVTest = test\n",
    "        self.LOOCVAntiTestSet = self.LOOCVTrain.build_anti_testset()\n",
    "        \n",
    "        # Now compute sim matrix between users to measure diversity\n",
    "        self.simAlgo = KNNBaseline(\n",
    "            sim_options={'name': 'cosine', 'user_based': True}\n",
    "        )\n",
    "        self.simAlgo.fit(self.full_trainset)\n",
    "        \n",
    "        \n",
    "    def get_full_trainset(self):\n",
    "        return self.full_trainset\n",
    "    \n",
    "    def get_full_anti_testset(self):\n",
    "        return self.full_anti_testset\n",
    "    \n",
    "    def get_trainset(self):\n",
    "        return self.trainset\n",
    "    \n",
    "    def get_testset(self):\n",
    "        return self.testset\n",
    "    \n",
    "    def get_LOOCV_testset(self):\n",
    "        return self.LOOCVTest\n",
    "    \n",
    "    def get_LOOCV_trainset(self):\n",
    "        return self.LOOCVTrain\n",
    "    \n",
    "    def get_LOOCV_anti_testset(self):\n",
    "        return self.LOOCVAntiTestSet\n",
    "    \n",
    "    def get_rankings(self):\n",
    "        return self.rankings\n",
    "    \n",
    "    def get_sims(self):\n",
    "        return self.simAlgo\n",
    "\n",
    "class Algorithm:\n",
    "    \n",
    "    def __init__(self, name, algorithm):\n",
    "        self.name = name\n",
    "        self.algo = algorithm\n",
    "        \n",
    "    def evaluate(self, eval_data):\n",
    "        metrics = {}\n",
    "        \n",
    "        # Compute accuracy\n",
    "        print(\"Evaluating accuracy...\")\n",
    "        self.algo.fit(eval_data.get_trainset())\n",
    "        preds = self.algo.test(eval_data.get_testset())\n",
    "        metrics['RMSE'] = Metrics.RMSE(preds)\n",
    "        metrics['MAE'] = Metrics.MAE(preds)\n",
    "        \n",
    "        # Eval top-10 via leave-one-out\n",
    "        print(\"Evaluating top-10 with LOOCV..\")\n",
    "        self.algo.fit(eval_data.get_LOOCV_trainset())\n",
    "        lo_preds = self.algo.test(eval_data.get_LOOCV_testset())\n",
    "            \n",
    "        # Generate preds for ratings not in training\n",
    "        all_preds = self.algo.test(eval_data.get_LOOCV_anti_testset())\n",
    "      \n",
    "        # Get top 10 recs per user\n",
    "        topN_preds = Metrics.get_topN(all_preds, 10)\n",
    "        \n",
    "        print('Evaluating rank metrics...')\n",
    "        # Hit-rate - how often a movie that the user liked was recommended\n",
    "        metrics['HR'] = Metrics.hit_rate(topN_preds, lo_preds)\n",
    "        # Cumulative-hit-rate\n",
    "        metrics['CHR'] = Metrics.cumulative_hit_rate(topN_preds, lo_preds)\n",
    "\n",
    "        metrics[\"ARHR\"] = Metrics.avg_reciprocal_hit_rate(topN_preds, lo_preds)\n",
    "\n",
    "        print('Computing recs with complete dataset...')\n",
    "        self.algo.fit(eval_data.get_full_trainset())\n",
    "        all_preds = self.algo.test(eval_data.get_full_anti_testset())\n",
    "        topN_preds = Metrics.get_topN(all_preds, 10)\n",
    "        \n",
    "        metrics['Coverage'] = Metrics.user_coverage(topN_preds, eval_data.get_full_trainset().n_users)\n",
    "        metrics['Diversity'] = Metrics.diversity(topN_preds, eval_data.get_sims())\n",
    "        metrics['Novelty'] = Metrics.novelty(topN_preds, eval_data.get_rankings())\n",
    "        \n",
    "        print('Done.')\n",
    "        \n",
    "        return metrics\n",
    "        \n",
    "        \n",
    "class Evaluator:\n",
    "    algorithms = []\n",
    "    \n",
    "    def __init__(self, data, rankings):\n",
    "        self.data = EData(data, rankings)\n",
    "    \n",
    "    def add_algorithm(self, name, algorithm):\n",
    "        self.algorithms.append(Algorithm(name, algorithm))\n",
    "    \n",
    "    def evaluate(self):\n",
    "        results = {}\n",
    "        for algo in self.algorithms:\n",
    "            print(f'Evaluating {algo.name}...')\n",
    "            results[algo.name] = algo.evaluate(self.data)\n",
    "        \n",
    "        # Display results\n",
    "        print()\n",
    "        print(\"{:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10}\".format(\"Algorithm\", \"RMSE\", \"MAE\", \"HR\", \"CHR\", \"ARHR\", \"Coverage\", \"Diversity\", \"Novelty\" ))\n",
    "\n",
    "        for name, metrics in results.items():\n",
    "                print(\"{:<10} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f}\".format(\n",
    "                        name, metrics[\"RMSE\"], metrics[\"MAE\"], metrics[\"HR\"], metrics[\"CHR\"],  metrics[\"ARHR\"], metrics[\"Coverage\"], metrics[\"Diversity\"], metrics[\"Novelty\"]))\n",
    "     \n",
    "    \n",
    "    \n",
    "class Metrics:\n",
    "    \n",
    "    def MAE(predictions):\n",
    "        return accuracy.mae(predictions, verbose=False)\n",
    "    \n",
    "    def RMSE(predictions):\n",
    "        return accuracy.rmse(predictions, verbose=False)\n",
    "    \n",
    "    def get_topN(predictions, n=10):\n",
    "        top_n = defaultdict(list)\n",
    "        for uid, iid, actual, estimated, _ in predictions:\n",
    "            if (estimated > 1.0): # >1 is min rating\n",
    "                top_n[int(uid)].append((int(iid), estimated))\n",
    "                \n",
    "        for uid, ratings in top_n.items():\n",
    "            ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "            top_n[int(uid)] = ratings[:n]\n",
    "        \n",
    "        return top_n\n",
    "        \n",
    "    def hit_rate(top_n_preds, left_out_preds):\n",
    "        \"\"\"Determine the hit-rate (how good) of top-N list\"\"\"\n",
    "        hits = 0\n",
    "        total = 0\n",
    "        for lo_pred in left_out_preds:\n",
    "            lo_uid = lo_pred[0]\n",
    "            lo_iid = lo_pred[1]\n",
    "            \n",
    "            # Check if in top 10\n",
    "            is_hit = False\n",
    "            for tn_iid, tn_pred in top_n_preds[int(lo_uid)]:\n",
    "                if (int(lo_iid) == int(tn_iid)):\n",
    "                    is_hit = True\n",
    "                    break\n",
    "            if is_hit:\n",
    "                hits += 1\n",
    "            total += 1\n",
    "            \n",
    "        precision = hits / total\n",
    "        return precision\n",
    "            \n",
    "    \n",
    "    def cumulative_hit_rate(topN_preds, left_out_preds):\n",
    "        hits = 0\n",
    "        total = 0\n",
    "        for lo_uid, lo_iid, actual, estimated, _ in left_out_preds:\n",
    "            if (actual == 1.0): # Only look at things the user starred\n",
    "                is_hit = False\n",
    "                for tn_iid, tn_pred in topN_preds[int(lo_uid)]:\n",
    "                    if (int(lo_iid) == tn_iid):\n",
    "                        is_hit = True\n",
    "                        break\n",
    "                if is_hit:\n",
    "                    hits += 1\n",
    "                total += 1\n",
    "        precision = hits/total\n",
    "        return precision\n",
    "    \n",
    "    def avg_reciprocal_hit_rate(topN_preds, left_out_preds):\n",
    "        S = 0\n",
    "        total = 0\n",
    "        for lo_uid, lo_iid, actual, estimated, _ in left_out_preds:\n",
    "            hit_rank = 0\n",
    "            rank = 0\n",
    "            for tn_iid, tn_pred in topN_preds[int(lo_uid)]:\n",
    "                rank += 1\n",
    "                if (int(lo_iid) == tn_iid):\n",
    "                    hit_rank = rank\n",
    "                    break\n",
    "            if hit_rank > 0:\n",
    "                S += 1.0 / hit_rank\n",
    "            total += 1\n",
    "        return S / total\n",
    "    \n",
    "    def user_coverage(topN_preds, num_users):\n",
    "        # Calc the percentage of users that have at least 1 good rec\n",
    "        hits = 0\n",
    "        for tn_uid in topN_preds.keys():\n",
    "            is_hit = False\n",
    "            for tn_iid, tn_pred in topN_preds[tn_uid]:\n",
    "                if tn_pred > 1.0: # Todo is 1 correct number to use??\n",
    "                    is_hit = True\n",
    "                    break\n",
    "            if is_hit:\n",
    "                hits += 1\n",
    "        return hits / num_users\n",
    "    \n",
    "    \n",
    "    # TODO: NOVELTY AND DIVERSITY ARE NOT WORKING -- most likely due to topN_preds not working??\n",
    "    def diversity(topN_preds, sim_algorithm):\n",
    "        n = 0\n",
    "        total = 0\n",
    "        mat = sim_algorithm.compute_similarities()\n",
    "        for uid in topN_preds.keys():\n",
    "            pairs = itertools.combinations(topN_preds[uid], 2)\n",
    "            for pair in pairs:\n",
    "                repo1 = pair[0][0]\n",
    "                repo2 = pair[1][0]\n",
    "                if sim_algorithm.trainset.knows_item(repo1) and sim_algorithm.trainset.knows_item(repo2):\n",
    "                    inner_id1 = sim_algorithm.trainset.to_inner_iid(repo1) # used to be str(repo1)\n",
    "                    inner_id2 = sim_algorithm.trainset.to_inner_iid(repo2)\n",
    "                    sim = mat[inner_id1][inner_id2]\n",
    "                    total += sim\n",
    "                    n += 1\n",
    "        return 0 # 1 - (total / n) \n",
    "    \n",
    "    def novelty(topN_preds, rankings):\n",
    "        n = 0\n",
    "        total = 0\n",
    "        for uid in topN_preds.keys():\n",
    "            for rating in topN_preds[uid]:\n",
    "                iid = rating[0]\n",
    "                rank = rankings[iid]\n",
    "                total += rank\n",
    "                n += 1\n",
    "        return 0 # total / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4556c99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<__main__.Algorithm at 0x165959490>, <__main__.Algorithm at 0x1327fe160>]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and process our data\n",
    "reader = Reader(rating_scale=(1, 2))\n",
    "data = Dataset.load_from_df(temp[['user_id', 'repo_id', 'rating']], reader)\n",
    "\n",
    "# setup an evaluator\n",
    "evaluator = Evaluator(data, repo_rankings)\n",
    "\n",
    "# USER-BASED KNN\n",
    "user_knn = KNNBasic(sim_options={'name': 'cosine', 'user_based': True})\n",
    "\n",
    "# SVD\n",
    "svd = SVD()\n",
    "\n",
    "# TODO: add social network stuff\n",
    "# following_triads = FollowingTriadsAlgo()\n",
    "# follower_triads = FollowerTriadsAlgo()\n",
    "# followee_and_follower_net = FolloweeFollowerNet(type='and')\n",
    "# followee_or_follower_net = FolloweeFollowerNet(type='or')\n",
    "\n",
    "# Add the algorithms\n",
    "evaluator.add_algorithm('User KNN', user_knn)\n",
    "evaluator.add_algorithm('SVD', svd)\n",
    "\n",
    "evaluator.algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e42c9126",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating User KNN...\n",
      "Evaluating accuracy...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating top-10 with LOOCV..\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating rank metrics...\n",
      "Computing recs with complete dataset...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done.\n",
      "Evaluating SVD...\n",
      "Evaluating accuracy...\n",
      "Evaluating top-10 with LOOCV..\n",
      "Evaluating rank metrics...\n",
      "Computing recs with complete dataset...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done.\n",
      "\n",
      "Algorithm  RMSE       MAE        HR         CHR        ARHR       Coverage   Diversity  Novelty   \n",
      "User KNN   0.1684     0.0420     0.4234     0.4157     0.4234     0.0000     0.0000     0.0000    \n",
      "SVD        0.1669     0.0570     0.8468     0.8439     0.8468     0.0000     0.0000     0.0000    \n"
     ]
    }
   ],
   "source": [
    "# Run the evals\n",
    "evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d691fad",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Use of multiple measures to evaluate the final system quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ba616d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
